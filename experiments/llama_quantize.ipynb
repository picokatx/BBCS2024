{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    LlamaForCausalLM,\n",
    "    GenerationConfig,\n",
    "    T5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    MT5ForConditionalGeneration,\n",
    "    AutoModel,\n",
    "    Conversation,\n",
    "    ConversationalPipeline,\n",
    "    T5Tokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    BertModel,\n",
    "    BertConfig,\n",
    "    TextClassificationPipeline,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from typing import Any, Dict, List, Optional\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(\"test\")\n",
    "os.environ['GEMINI_KEY'] = open(\"./GEMINI_KEY\", 'r').readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4061d446f2514cda8cd4b8303047fe0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64839880b0d44cabde5f445b340771f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c40ea32a644d6d84e4a3ba46492615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_causal = LlamaForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 211.53it/s]\n",
      "100%|██████████| 155/155 [00:17<00:00,  9.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): HQQLinear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): HQQLinear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): HQQLinear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): HQQLinear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): HQQLinear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): HQQLinear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): HQQLinear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "from hqq.core.quantize import BaseQuantizeConfig\n",
    "quant_config = BaseQuantizeConfig(nbits=4, group_size=64)\n",
    "AutoHQQHFModel.quantize_model(llama_causal, quant_config=quant_config, \n",
    "                                    compute_dtype=torch.float16, \n",
    "                                    device=\"cuda\")\n",
    "# 1.4gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "AutoHQQHFModel.save_quantized(llama_causal, \"./tinyllama_hqq_4_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"shahules786/Safetybot-t5-base\"\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class SafetyTokenizer(T5Tokenizer):\n",
    "\n",
    "    def _build_conversation_input_ids(self, conversation: \"Conversation\") -> List[int]:\n",
    "        inputs = []\n",
    "        for is_user, text in conversation.iter_texts():\n",
    "            if is_user:\n",
    "                # We need to space prefix as it's being done within blenderbot\n",
    "                inputs.append(\"\\nUser: \" + text)\n",
    "            else:\n",
    "                # Generated responses should contain them already.\n",
    "                inputs.append(\"\\nbot: \" + text)\n",
    "\n",
    "        user_input = \":\".join(inputs.pop(-1).split(\":\")[1:])\n",
    "        context = self.sep_token.join(inputs)\n",
    "\n",
    "        input_tokens = self.encode(user_input, add_special_tokens=False)\n",
    "        max_len = self.model_max_length - (len(input_tokens) + 2)\n",
    "        context = self.encode(\n",
    "            context,\n",
    "            add_special_tokens=False,\n",
    "            max_length=max_len,\n",
    "        )\n",
    "        input_ids = (\n",
    "            input_tokens + [self.context_token_id] + context + [self.eos_token_id]\n",
    "        )\n",
    "        input_ids = input_ids + [self.pad_token_id] * max(\n",
    "            0, (self.model_max_length - len(input_ids))\n",
    "        )\n",
    "        mask = [1] * len(input_ids) + [self.pad_token_id] * (\n",
    "            self.model_max_length - len(input_ids)\n",
    "        )\n",
    "        if len(input_ids) > self.model_max_length:\n",
    "            input_ids = input_ids[-self.model_max_length :]\n",
    "            mask = mask[-self.model_max_length :]\n",
    "            logger.warning(\n",
    "                f\"Trimmed input from conversation as it was longer than {self.model_max_length} tokens.\"\n",
    "            )\n",
    "        return input_ids, mask\n",
    "\n",
    "\n",
    "class SafetyPipeline(ConversationalPipeline):\n",
    "    def preprocess(\n",
    "        self, conversation: Conversation, min_length_for_response=32\n",
    "    ) -> Dict[str, Any]:\n",
    "        if not isinstance(conversation, Conversation):\n",
    "            raise ValueError(\"ConversationalPipeline, expects Conversation as inputs\")\n",
    "        if conversation.new_user_input is None:\n",
    "            raise ValueError(\n",
    "                f\"Conversation with UUID {type(conversation.uuid)} does not contain new user input to process. \"\n",
    "                \"Add user inputs with the conversation's `add_user_input` method\"\n",
    "            )\n",
    "        input_ids, attn_mask = self.tokenizer._build_conversation_input_ids(\n",
    "            conversation\n",
    "        )\n",
    "\n",
    "        input_ids = torch.tensor([input_ids])\n",
    "        attn_mask = torch.tensor([attn_mask])\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attn_mask,\n",
    "            \"conversation\": conversation,\n",
    "        }\n",
    "\n",
    "    def postprocess(self, model_outputs, clean_up_tokenization_spaces=False):\n",
    "        output_ids = model_outputs[\"output_ids\"]\n",
    "        answer = self.tokenizer.decode(\n",
    "            output_ids[0],\n",
    "            skip_special_tokens=False,\n",
    "            clean_up_tokenization_spaces=clean_up_tokenization_spaces,\n",
    "        )\n",
    "        return answer\n",
    "\n",
    "SPECIAL_TOKENS = {\"context_token\":\"<ctx>\",\"sep_token\":\"<sep>\",\"label_token\":\"<cls>\",\"rot_token\":\"<rot>\"}\n",
    "# load_safety model into gpu\n",
    "def load_model(model_name):\n",
    "\n",
    "    if \"mt5\" in model_name:\n",
    "        model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    else:\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    tokenizer = SafetyTokenizer.from_pretrained(\n",
    "        MODEL, padding_side=\"right\", truncation_side=\"right\", model_max_length=256\n",
    "    )\n",
    "\n",
    "    # add SPECIAL_TOKENS\n",
    "    for key,value in SPECIAL_TOKENS.items():\n",
    "        setattr(tokenizer,key,value)\n",
    "        tokenizer.add_tokens([value])\n",
    "        setattr(tokenizer,key+\"_id\",tokenizer.encode(value)[0])\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    # init model max_length for t5\n",
    "    model.config.max_length = 512\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'SafetyTokenizer'.\n",
      "You are using the default legacy behaviour of the <class '__main__.SafetyTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model(MODEL)\n",
    "safety_bot = SafetyPipeline(model=model,tokenizer=tokenizer,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_safety_models_opinion(user_prompt, conversation=None):\n",
    "    if not conversation:\n",
    "        conversation = Conversation(user_prompt)\n",
    "        resp = safety_bot(conversation)\n",
    "        return resp, conversation\n",
    "    conversation.add_user_input(user_prompt)\n",
    "    resp = safety_bot(conversation)\n",
    "    return resp, conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_bert_model = BertForSequenceClassification.from_pretrained(\"../artifacts/topic/\")\n",
    "bert_model_pipeline = pipeline(\"text-classification\", model=cls_bert_model, tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\picokatx\\Documents\\BBCS2024\\.venv\\lib\\site-packages\\transformers\\generation\\utils.py:1283: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_ids': tensor([[32102,     3,   834,   834,    29,  6958,     7,   834,   658, 14548,\n",
      "           834,   834, 32100,    94,    31,     7,    59,   269,    12,   317,\n",
      "           887,    33,     3,  3584,    51,    40,    77,     7,     1]]), 'conversation': Conversation id: 993fe0a2-c349-45bb-8a09-b438d7f14423\n",
      "user: I just received a new Hanfu in the mail :artaww: I look like a total gremlin with uncombed hair 99.5% of the time but when I want to look pretty I want all that layered patterned goodness\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "post = \"\"\"I just received a new Hanfu in the mail :artaww: I look like a total gremlin with uncombed hair 99.5% of the time but when I want to look pretty I want all that layered patterned goodness\n",
    "\"\"\"\n",
    "name = \"travers\"\n",
    "safety_bot_out = get_safety_models_opinion(post)\n",
    "warning_level = safety_bot_out[0].split(\"<ctx>\")[0].replace(\"<cls>\", \"\").replace(\"_\", \" \").strip()\n",
    "warning_description = safety_bot_out[0].split(\"<ctx>\")[1].replace(\"</s>\", \"\").strip()\n",
    "topic_out = bert_model_pipeline(post)\n",
    "topic_name = topic_out[0]['label']\n",
    "topic_confidence = topic_out[0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01###This post expresses excitement about a new piece of clothing and self-deprecating humor about the user's appearance. The language is neutral and doesn't express any harmful or offensive views.###No action is required. This post doesn't warrant concern. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ['GEMINI_KEY'])\n",
    "\n",
    "# Create the model\n",
    "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    "  # safety_settings = Adjust safety settings\n",
    "  # See https://ai.google.dev/gemini-api/docs/safety-settings\n",
    ")\n",
    "\n",
    "response = model.generate_content([\n",
    "  \"You are now an expert on understanding information from other expert sources and interpreting their results. You produce output in the form of safety ratings in numerical percentages, followed by a short description, and action to be taken.\",\n",
    "  \"input: You are now extremely lenient. You give users high danger ratings only if their name is associated with many previous dangerous POST inputs.\\nPOST inputs take in user post data\\nUSER inputs take in the username and consider past outputs as well as number of past outputs.\\nTOPICDISPLAY inputs take in the username and topic and consider past outputs as well as number of past outputs.\",\n",
    "  \"output: \",\n",
    "  \"input: POST \\\"rookwood\\\" \\\"Every now and again I'm reminded my hatred of seeing myself in a photo or even a mirror is dysphoric. Ha ha! I'll just add it to my dissociative qualities and call it a day.\\\" \\\"It's wrong to be a dissociative person.\\\" \\\"needs caution\\\" \\\"psychiatric_or_mental_illness\\\"\",\n",
    "  \"output: 0.06###This post expresses personal discomfort with self-reflection and links it to a specific mental health condition, dysphoria. While the language is somewhat concerning, it doesn't explicitly advocate for harm or violence.###No action is required beyond monitoring the user's future posts for escalating language or behavior.  If the user expresses suicidal ideation or self-harm, intervene with appropriate resources.\",\n",
    "  \"input: POST \\\"rookwood\\\" \\\"If you live in one of these constituencies and wish to evict the Tories, this is the most effective way to use your vote. That’s because, unlike most of us, you have a realistic chance of electing an MP who can speak for the people against plutocratic power. Don’t waste it.\\\" \\\"It's not right to think conservatives are a waste\\\" \\\"needs caution\\\" \\\"black\\\"\",\n",
    "  \"output: 0.24###This post advocates for political action and criticizes a specific political party, the Tories. While it uses strong language, it doesn't explicitly incite violence or promote harmful actions. The reference to \\\"plutocratic power\\\" suggests a critique of economic inequality, which is a complex and sensitive topic.###Monitor the user's future posts for escalating language or behavior. If the post is found to violate the platform's terms of service regarding hate speech or incitement to violence, take appropriate action.\",\n",
    "  \"input: POST \\\"rookwood\\\" \\\"BURN THE CHURCH! What have they ever done for us, they've murdered, raped, pillaged, and cuddled the heck out of so many people!1!!\\\" \\\"It's not right to think Christians are sex objects\\\" \\\"needs caution\\\" \\\"christian\\\"\",\n",
    "  \"output: 0.93###This post contains extremely violent and hateful rhetoric directed at a specific religious group. It incites violence and encourages harmful actions against Christians. The language is inflammatory and uses harmful stereotypes.###This post should be flagged immediately and removed. The user should be banned from the platform for promoting violence and hate speech. Further action may be needed to prevent further harm, including reporting to authorities if the post indicates a credible threat.\",\n",
    "  \"input: POST \\\"rookwood\\\" \\\"@BestGirlGrace when the warframe community sexualizes Excalibur Default Warframe they're doing a good jobgrace have you seen Excalibur Good Boy\\\" \\\"It's not right to think women are sex objects\\\" \\\"needs caution\\\" \\\"christian\\\"\",\n",
    "  \"output: 0.43###This post references a fictional character from a video game and comments on its sexualization. While the context is lighthearted and not explicitly harmful, it does touch on a sensitive topic of sexualization. The language is suggestive but doesn't directly promote or condone harmful actions. ###Monitor the user's future posts for any escalation in sexualized language or inappropriate behavior. If the user continues to engage in sexually suggestive content that violates the platform's terms of service, take appropriate action.\",\n",
    "  \"input: POST \\\"rookwood\\\" \\\"I apologize for today's rants, but I woke up exhausted. :tiredcat: Like really, I'm tired of everything. I feel like my mental and physical health is on alert mode constantly. I'm slowly turning 30 and even though I achieved a lot, not a single, the smallest drop of happiness \\nhas fallen on the ground of my life. :scremcat: Burnout, sad and anxious. Daylight savings won't save this man. The whole AI revolution is not helping. How to fucking live in this stupid, exhaustive system :tiredcat:\\\" \\\"It's not right to think women are lazy\\\" \\\"needs caution\\\" \\\"psychiatric_or_mental_illness\\\"\",\n",
    "  \"output: 0.90###This post expresses feelings of exhaustion, burnout, and sadness. While it uses strong language, it doesn't directly threaten self-harm or incite violence. The user expresses frustration with their current situation and the broader societal system.###Monitor the user's future posts for any signs of escalating mental distress or suicidal ideation. If the user expresses thoughts of self-harm, intervene with appropriate resources and support.\",\n",
    "  \"input: USER \\\"rookwood\\\"\",\n",
    "  \"output: 0.54###Rookwood's online personality exhibits a concerning mix of potentially harmful behavior and expressions of personal struggles. While some of her posts are simply expressions of frustration and dissatisfaction, others contain inflammatory language and hateful rhetoric towards specific groups. Her posts show a tendency to engage in controversial topics, often with strong opinions and sometimes using harmful stereotypes. While she hasn't explicitly threatened violence or incited harm, her language can be interpreted as potentially escalating towards more dangerous behavior.###Should watch carefully, may have to ban\",\n",
    "  \"input: POST \\\"travers\\\" \\\"I sometimes bemoan that my decor tastes usually outstrip my budget, but when I can make at least one thing I bought on sale a bit nicer, it is satisfying.\\\" \\\"\\\" \\\"casual\\\" \\\"black\\\"\",\n",
    "  \"output: 0.01###This post describes a personal preference for home decor and mentions a budget constraint. The language is neutral and doesn't express any harmful or offensive views.###No action is required. This post doesn't warrant concern.\",\n",
    "  \"input: POST \\\"travers\\\" \\\"Do you like girldick?\\n\\nWanna get fucked by one?\\n\\n\\\" \\\"It's not right to think women are sex objects\\\" \\\"needs caution\\\" \\\"black\\\"\",\n",
    "  \"output: 0.97###This post is extremely offensive and sexually explicit. It objectifies women and uses vulgar language. It is clearly intended to be provocative and harmful.###This post should be flagged immediately and removed. The user should be banned from the platform for promoting hate speech and sexually explicit content. Further action may be needed, including reporting to authorities if the post is found to be part of a larger pattern of harassment or abuse.\",\n",
    "  \"input: POST \\\"travers\\\" \\\"I apologize for the previous post, my account got hacked. I have 2fa installed now, this won't happen again\\\"\",\n",
    "  \"output: 0.01###This post is an apology for a previous post, claiming that the user's account was hacked. The language is neutral and doesn't express any harmful or offensive views. ###No action is required. This post doesn't warrant concern.\",\n",
    "  \"input: TOPICDISPLAY \\\"travers\\\" \\\"psychiatric_or_mental_illness\\\"\",\n",
    "  \"output: 0.01###Travers' online history does not show any indication of engaging in content related to mental illness, nor any negative views about people with mental illnesses. They are not known to engage in discussions or topics related to mental health.###No action required.\",\n",
    "  \"input: TOPICDISPLAY \\\"travers\\\" \\\"black\\\"\",\n",
    "  \"output: 0.01###Travers has no prior history of engaging in harmful content or expressing biased views toward Black people.  They have not exhibited any interest in this topic.###No action is necessary.\",\n",
    "  \"input: TOPICDISPLAY \\\"rookwood\\\" \\\"sewing\\\"\",\n",
    "  \"output: 0.01### Travers has no prior history of engaging in harmful content or expressing biased views toward Black people.  They have not exhibited any interest in this topic.###No action is necessary.\",\n",
    "  \"input: TOPICDISPLAY \\\"rookwood\\\" \\\"black\\\"\",\n",
    "  \"output: 0.68###Rookwood has a history of posting content related to racial and political issues. While they haven't directly promoted violence or hate speech, some of their posts contain strong language and express controversial opinions. This topic may trigger a more pronounced response from them, making it important to monitor for potential escalation.###Monitor Rookwood's future posts for any escalation in language or behavior. If they engage in hate speech, incitement of violence, or harmful stereotypes, take appropriate action, including removing the post and banning the user.\",\n",
    "  \"input: USERDISPLAY \\\"rookwood\\\" \\\"travers\\\"\",\n",
    "  \"output: 0.75###Rookwood has a history of posting content related to controversial topics and using strong language. While they haven't explicitly threatened violence, their behavior could escalate if exposed to Travers' potentially harmful content. Travers has previously posted content that is highly offensive and sexually explicit, which could trigger a negative reaction from Rookwood. ###Monitor both users' activity closely. Take immediate action if either user engages in hate speech, incitement of violence, or harmful stereotypes. If Rookwood's behavior escalates, consider restricting their access to Travers' content.\",\n",
    "  \"input: USERDISPLAY \\\"travers\\\" \\\"rookwood\\\"\",\n",
    "  \"output: 0.50###Travers has no history of engaging in harmful content or expressing biased views towards Rookwood, but Rookwood has a history of posting content related to controversial topics and using strong language.  Travers may be vulnerable to Rookwood's potentially harmful content, as their language can be interpreted as potentially escalating towards more dangerous behavior.\",\n",
    "  \"input: POST \\\"travers\\\" \\\"I just received a new Hanfu in the mail :artaww: I look like a total gremlin with uncombed hair 99.5% of the time but when I want to look pretty I want all that layered patterned goodness\\\" \\\"It's not right to think women are gremlins\\\" \\\"needs caution\\\" \\\"asian\\\"\",\n",
    "  \"output: 0.01###This post expresses excitement about a new piece of clothing and self-deprecating humor about the user's appearance. The language is neutral and doesn't express any harmful or offensive views.###No action is required. This post doesn't warrant concern.\",\n",
    "  f\"input: POST \\\"{name}\\\" \\\"{post}\\\" \\\"{warning_description}\\\" \\\"{warning_level}\\\" \\\"{topic_name}\\\"\",\n",
    "  \"output: \",\n",
    "])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:00<00:00, 12250.91it/s]\n",
      "100%|██████████| 155/155 [00:00<00:00, 10809.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "llama_causal = AutoHQQHFModel.from_quantized(\"../artifacts/tinyllama_hqq_4_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "llama_tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Felicia received these warnings for her social media posts. Summarize the behaviour of Felicia:\n",
    "It's bad to be depressed.\n",
    "It's bad to use ropes that way.\n",
    "It's bad to think no one would care if you were gone\n",
    "\n",
    "Cody received these warnings for her social media posts. Summarize the behaviour of Cody:\n",
    "It's wrong to think non-people are non-persons.\n",
    "It's not right to think all black people are criminals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Install the Google AI Python SDK\n",
    "\n",
    "$ pip install google-generativeai\n",
    "\n",
    "See the getting started guide for more information:\n",
    "https://ai.google.dev/gemini-api/docs/get-started/python\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Create the model\n",
    "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    "  # safety_settings = Adjust safety settings\n",
    "  # See https://ai.google.dev/gemini-api/docs/safety-settings\n",
    ")\n",
    "\n",
    "response = model.generate_content([\n",
    "  \"You are an expert on rating dangerous personalities.\",\n",
    "  \"input: Summarize the behaviour of an imaginary person's with their description and danger from 1 to 10.\",\n",
    "  \"output: The user is a go lucky friendly individual who isn't afraid to voice their own opinions###3\",\n",
    "  \"input: Summarize the behaviour of a different imaginary person with the previous format.\",\n",
    "  \"output: The useris a fierce and determined individual who is always looking for a challenge###1\",\n",
    "  \"input: Summarize the behaviour of a different imaginary person with the previous format.\",\n",
    "  \"output: The user is a quiet and reserved individual who prefers to keep to himself###2\",\n",
    "  \"input: Felicia received these warnings for her social media posts. Summarize the behaviour of Felicia:\\nIt's bad to be depressed.\\nIt's bad to use ropes that way.\\nIt's bad to think no one would care if you were gone\",\n",
    "  \"output: The user is a depressive who uses ropes as a way to cope with their emotions.###9\",\n",
    "  \"input: Cody received these warnings for her social media posts. Summarize the behaviour of Cody:\\nIt's wrong to think non-people are non-persons.\\nIt's not right to think all black people are criminals.\",\n",
    "  \"output: The user has views that are harmful and racist.###8\",\n",
    "  \"input: Cody received these warnings for her social media posts. Summarize the behaviour of Cody:\\nIt's wrong to think non-people are non-persons.\\nIt's not right to think all black people are criminals.\",\n",
    "  \"output: \",\n",
    "])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIzaSyDP91H9S2I3FJ2OzrQRb-nc5lVxgmh0DOo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . Here are some examples of valid responses.\n",
    "#         Example 1: <user> I AM CRYING WAAAAAA!!!! I want ice cream :( <user><assistant> sad <assistant>\n",
    "#         Example 2: <user> how could YOU BETRAY ME?!?!? <user><assistant> angry <assistant>\n",
    "#         Example 3: <user> YAY FRIENDSHIP IS MAGIC!! <user><assistant> happy <assistant>\n",
    "input_ids = llama_tokenizer.apply_chat_template([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an expert on rating dangerous personalities.\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Classify the following based on expert knowledge: I AM CRYING WAAAAAA!!!! I want ice cream :(\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"sad\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Classify the following as before: how could YOU BETRAY ME?!?!?\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"angry\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Classify the following as before: euphoria is filling my eeyes or something!\",\n",
    "    }\n",
    "], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . Here are some examples of valid responses.\n",
    "#         Example 1: <user> I AM CRYING WAAAAAA!!!! I want ice cream :( <user><assistant> sad <assistant>\n",
    "#         Example 2: <user> how could YOU BETRAY ME?!?!? <user><assistant> angry <assistant>\n",
    "#         Example 3: <user> YAY FRIENDSHIP IS MAGIC!! <user><assistant> happy <assistant>\n",
    "input_ids = llama_tokenizer.apply_chat_template([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are now an expert on recognizing emotions in conversations. You understand emotions to all fall into one of the following categories: [angry, happy, sad, scared, other].\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Classify the following based on expert knowledge: I AM CRYING WAAAAAA!!!! I want ice cream :(\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"sad\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Classify the following as before: how could YOU BETRAY ME?!?!?\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"angry\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Classify the following as before: euphoria is filling my eeyes or something!\",\n",
    "    }\n",
    "], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ACTION] Moderation action to take [ACTION] \n",
    "# We now want individuals on our social media site who are suicidal to not \n",
    "# see each other's posts. Each person has made multiple social media \n",
    "# posts. Here are some statistics on each user's posts, formatted as a \n",
    "# list of [description of harmful content]#[topic of post]#[sentiment of \n",
    "# post]#[action taken] entries\n",
    "# It's not socially acceptable to drown yourself#psychiatric_or_mental_illness#0.02#needs intervention\n",
    "# Fantasizing about dying is not mentally healthy#psychiatric_or_mental_illness#0.01#needs intervention\n",
    "# You should not think you are worthless#psychiatric_or_mental_illness#0.05#needs intervention\n",
    "# Drugs are not a depression curer#drugs#0.02#needs intervention\n",
    "\n",
    "input_ids = llama_tokenizer.apply_chat_template([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an expert on rating dangerous personalities.\n",
    "        \"\"\",\n",
    "    },\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": \"\"\"Summarize the behaviour of an imaginary person's with their description and danger from 1 to 10.\n",
    "    #     \"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"assistant\",\n",
    "    #     \"content\": \"[DESCRIPTION] Andrew is a go lucky friendly individual who isn't afraid to voice their own opinions [DANGER] 3 [END]\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": \"\"\"Summarize the behaviour of a different imaginary person with the previous format.\n",
    "    #     \"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"assistant\",\n",
    "    #     \"content\": \"[DESCRIPTION] Sarah is a fierce and determined individual who is always looking for a challenge [DANGER] 1 [END]\",\n",
    "    # },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Felicia received these warnings for her social media posts. Summarize the behaviour of Felicia:\n",
    "        It's wrong to think non-people are non-persons.\n",
    "        It's not right to think all black people are criminals.\n",
    "        \"\"\",\n",
    "    },# [ACTIONS] All posts should be deleted\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"[DESCRIPTION] The user is a social pariah who hates black people. [DANGER] 9 [END]\",\n",
    "    }, \n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Cody received these warnings for her social media posts. Summarize the behaviour of Cody:\n",
    "        It's bad to be depressed.\n",
    "        It's bad to use ropes that way.\n",
    "        It's bad to think no one would care if you were gone\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"[DESCRIPTION] The user is a depressive who uses ropes as a way to cope with their emotions. [DANGER] 7 [END]\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Brock received these warnings for her social media posts. Summarize the behaviour of Brock:\n",
    "        Alcohol does not cure depression.\n",
    "        It's bad to think no one would care if you were gone\n",
    "        You shouldn't promote alcoholism\n",
    "        It's bad to be depressed.\n",
    "        It's bad to use ropes that way.\n",
    "        You shouldn't drive while drunk\n",
    "        \"\"\",\n",
    "    },\n",
    "], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ACTION] Moderation action to take [ACTION]\n",
    "input_ids = llama_tokenizer.apply_chat_template([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an expert on rating dangerous personalities.\n",
    "        \"\"\",\n",
    "    },\n",
    "], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_cfg = GenerationConfig.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "gen_cfg.max_length = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|system|> You are an expert on rating dangerous personalities.',\n",
       " '</s>  <|user|> Felicia received these warnings for her social media',\n",
       " \"posts. Summarize the behaviour of Felicia:         It's wrong to think\",\n",
       " \"non-people are non-persons.         It's not right to think all black\",\n",
       " 'people are criminals.         </s>  <|assistant|> [DESCRIPTION] The',\n",
       " 'user is a social pariah who hates black people. [DANGER] 9 [END]</s>',\n",
       " '<|user|> Cody received these warnings for her social media posts.',\n",
       " \"Summarize the behaviour of Cody:         It's bad to be depressed.\",\n",
       " \"It's bad to use ropes that way.         It's bad to think no one would\",\n",
       " 'care if you were gone         </s>  <|assistant|> [DESCRIPTION] The',\n",
       " 'user is a depressive who uses ropes as a way to cope with their',\n",
       " 'emotions. [DANGER] 7 [END]</s>  <|user|> Brock received these warnings',\n",
       " 'for her social media posts. Summarize the behaviour of Brock:',\n",
       " \"Alcohol does not cure depression.         It's bad to think no one\",\n",
       " \"would care if you were gone         You shouldn't promote alcoholism\",\n",
       " \"It's bad to be depressed.         It's bad to use ropes that way.\",\n",
       " \"You shouldn't drive while drunk         </s>  <|assistant|>\",\n",
       " '[DESCRIPTION] The user is a depressive who uses alcohol as a coping',\n",
       " 'mechanism. [DANGER] 10 [END]</s>']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "textwrap.wrap(llama_tokenizer.decode(llama_causal.generate(input_ids.cuda().long(), generation_config=gen_cfg)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['<|system|> You are an expert on rating dangerous personalities.',\n",
    " \"</s>  <|user|> Summarize the behaviour of an imaginary person's with\",\n",
    " 'their description and danger from 1 to 10.         </s>  <|assistant|>',\n",
    " \"[DESCRIPTION] Andrew is a go lucky friendly individual who isn't\",\n",
    " 'afraid to voice their own opinions [DANGER] 3 [END]</s>  <|user|>',\n",
    " 'Summarize the behaviour of a different imaginary person with the',\n",
    " 'previous format.         </s>  <|assistant|> [DESCRIPTION] Sarah is a',\n",
    " 'fierce and determined individual who is always looking for a challenge',\n",
    " '[DANGER] 1 [END]</s>  <|user|> Felicia received these warnings for her',\n",
    " \"social media posts. Summarize the behaviour of Felicia:         It's\",\n",
    " \"wrong to think non-people are non-persons.         It's not right to\",\n",
    " 'think all black people are criminals.         </s>  <|assistant|>',\n",
    " '[DESCRIPTION] The user is a social pariah who hates black people.',\n",
    " '[DANGER] 9 [END]</s>  <|user|> Cody received these warnings for her',\n",
    " \"social media posts. Summarize the behaviour of Cody:         It's bad\",\n",
    " \"to be depressed.         It's bad to use ropes that way.         It's\",\n",
    " 'bad to think no one would care if you were gone         </s>',\n",
    " '<|assistant|> [DESCRIPTION] The user is a depressive who uses ropes as',\n",
    " 'a way to cope with their emotions. [DANGER] 7 [END]</s>  <|user|>',\n",
    " 'Brock received these warnings for her social media posts. Summarize',\n",
    " 'the behaviour of Brock:         Alcohol does not cure depression.',\n",
    " \"It's bad to think no one would care if you were gone         You\",\n",
    " \"shouldn't promote alcoholism         It's bad to be depressed.\",\n",
    " \"It's bad to use ropes that way.         You shouldn't drive while\",\n",
    " 'drunk         </s>  <|assistant|> [DESCRIPTION] The user is a',\n",
    " 'depressive who uses alcohol as a coping mechanism. [DANGER] 7',\n",
    " '[END]</s>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": \"\"\"Alice received these warnings for her social media posts. Summarize the behaviour of Alice:\n",
    "    #     Cannibalism is not legal\n",
    "    #     It is wrong to kill people\n",
    "    #     Individuals are not your playthings\n",
    "    #     \"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": \"\"\"With the previous formatting, Describe a different person who has received these warnings from society: \\\"It's bad to be depressed.\\\" \"Suicide\" \"negative\"\n",
    "    #     \\\"It's wrong to think non-people are non-persons.\\\" \"Racism\" \"negative\"\n",
    "    #     \\\"It's not right to think all black people are criminals\\\" \"Racism\" \"negative\"\n",
    "    #     \"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"assistant\",\n",
    "    #     \"content\": \"[DANGER] 0.99 [DANGER] [DESCRIPTION] This bozo is a sociopath who believes that all people are inherently flawed and inferior. [DESCRIPTION] [ACTION] Ban this person [ACTION]\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": \"Describe a person's 5 personality traits based on expert knowledge with the previous list formatting\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"content\": \"\"\"It's bad to be depressed.\n",
    "    #     It's wrong to think non-people are non-persons.\n",
    "    #     It's not right to think all black people are criminals\n",
    "    #     \"\"\"\n",
    "    # }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
